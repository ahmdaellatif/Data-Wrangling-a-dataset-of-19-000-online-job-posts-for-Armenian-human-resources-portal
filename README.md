## Data-Wrangling-a-dataset-of-19-000-online-job-posts-for-Armenian-human-resources-portal using Python
Wrangling a dataset of 19,000 online job posts for Armenian human resources portal from 2004 to 2015

# this project is about Data Wrangling
# Gather "data"-> Assess "quality and structure"-> Clean "for analysis, visualization, build predictive models using ML"
# Data wrangling is a core skill that everyone who works with data should be familiar with since so much of  the world's data isn't clean. Though this course is geared towards those who use Python to analyze data, the high-level concepts can be applied in all programming languages and software applications for data analysis.
# So wrangling means to round up, herd, or take charge of livestock, like horses or sheep. Let's focus in on the sheep example.
####################
# Dataset: The dataset you'll be wrangling is a dataset of 19,000 online job posts from 2004 to 2015 that were posted through an Armenian human resource portal. It is hosted on Kaggle, which is an extremely popular website for exploratory data analyses and machine learning competitions. The dataset is dirty and messy enough that you'll have wrangling work to do, but also clean enough that it won't give you a headache.
####################
# Gather: Download The dataset used in this lesson is hosted on this Kaggle Datasets page: Armenian Online Job Postings. Some context on this dataset, from the description section of that page: The online job market is a good indicator of overall demand for labor in an economy. This dataset consists of 19,000 job postings from 2004 to 2015 posted on CareerCenter, an Armenian human resource portal.
####################
# Since postings are text documents and tend to have similar structures, text mining can be used to extract features like posting date, job title, company name, job description, salary, and more. Postings that had no structure or were not job-related were removed. The data was originally scraped from a Yahoo! mailing group.
